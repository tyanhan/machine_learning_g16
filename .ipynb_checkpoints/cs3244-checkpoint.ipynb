{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4acb7a-64dd-4107-9ee4-d0ee582724f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2 as cv\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imshow, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dff234-7a99-4b49-88af-0a40d98ef085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "\n",
    "file = glob.glob('./clothing-dataset-small-master.zip')\n",
    "\n",
    "with zipfile.ZipFile(file[0], 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0f5491-21de-454f-ab7e-d7dcc901a7df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17316\\4035382748.py:21: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  img = img.transpose(Image.FLIP_LEFT_RIGHT)\n"
     ]
    }
   ],
   "source": [
    "for data_type in [\"train\", \"validation\", \"test\"]:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "    \n",
    "    # combine validation and train\n",
    "    new_folder_path = \"./data/clothing-dataset/\" + (\"test\" if data_type == \"test\" else \"train\")\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                img.save(new_image_path)\n",
    "                                              \n",
    "                # flip all images besides t-shirts to balance the data\n",
    "                if folder != \"t-shirt\":\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    new_image_path = os.path.join(new_folder_path, folder, \"flipped_\" + filename)\n",
    "                    img.save(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ee3c49-c299-4622-9e8c-a91f49df841e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate HOG data from above data\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "    new_folder_path = \"./data/clothing-dataset-hog/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = cv.imread(image_path,cv.IMREAD_GRAYSCALE)\n",
    "                resized_img  = cv.resize(img, (64, 128),interpolation =cv.INTER_LINEAR)\n",
    "                fd, hog_image = hog(resized_img , orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True)\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                cv.imwrite(new_image_path, hog_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577498db-2c22-45a8-975d-95e6806d55ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate SIFT data from above data\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "    new_folder_path = \"./data/clothing-dataset-sift/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        \n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Apply the SIFT algorithm\n",
    "                sift = cv.SIFT_create()\n",
    "                keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "                # Draw the keypoints on the image\n",
    "                img_with_keypoints = cv.drawKeypoints(img, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "                # Save the image with keypoints to the new folder\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                cv.imwrite(new_image_path, img_with_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98320d99-d645-4720-97f3-7980eac9159f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Grayscale\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for data_type in [\"train\", \"test\"]:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                # resize the image\n",
    "                img = img.resize((64, 64))\n",
    "                # convert to grayscale\n",
    "                img = img.convert('L')\n",
    "                # flatten to 1D array\n",
    "                array = np.array(img).ravel()\n",
    "                \n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(array)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(array)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd1fb93-9d11-40a8-823f-cc4556c427c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow\n",
    "from skimage import transform\n",
    "from skimage.filters import prewitt\n",
    "\n",
    "def preprocess_image_edge_only(image):\n",
    "    resized_image = transform.resize(image, (64, 64), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 64 * 64)\n",
    "    return edges_prewitt_array[0]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = transform.resize(image, (64, 64), anti_aliasing=True)\n",
    "    edges_prewitt = prewitt(resized_image)\n",
    "    edges_prewitt_array = edges_prewitt.reshape(1, 64 * 64)\n",
    "    image_array = resized_image.reshape(1, 64 * 64)\n",
    "    return np.concatenate((edges_prewitt_array[0], image_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a22c5e0-d7bd-44b6-8275-fbc68bafb929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Edges\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image_edge_only(image)\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df749708-8851-430d-8acc-94382341a1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: Grayscale + Edges\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path,as_gray=True)\n",
    "                result = preprocess_image(image)\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e19cbf31-ceeb-4abf-a04a-7123e7175851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature: HOG\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset-hog/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path)\n",
    "                result = np.array(image).ravel()\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88eab1-3b96-46c5-b42c-185e1e67903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: SIFT\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset-sift/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path)\n",
    "                result = np.array(image).ravel()\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d608ef-a4fe-4205-91f9-eeec0d87c15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define the number of folds for cross validation\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "# define param search space for knn, dt, and rf\n",
    "knn_param_grid = {'n_neighbors': list(range(2, 100))}\n",
    "dt_param_grid = {'max_depth': list(range(2, 100))}\n",
    "rf_param_grid = {\n",
    "    # 'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': list(range(2, 100)),\n",
    "    # 'min_samples_split': [2, 5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4],\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# define models\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(max_features=512)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# define scoring metric\n",
    "f1_scorer = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0446c4-811f-4794-bb3d-4847852e8a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Best k:  {'n_neighbors': 8}\n",
      "Best F1 score:  0.5580628261873005\n",
      "Test F1 Score:  0.41907514450867056\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_model = RandomizedSearchCV(knn, knn_param_grid, cv=NUM_FOLDS, scoring=f1_scorer)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN:\")\n",
    "print(\"Best k: \", knn_model.best_params_)\n",
    "print(\"Best F1 score: \", knn_model.best_score_)\n",
    "\n",
    "knn_final = KNeighborsClassifier(n_neighbors=int(knn_model.best_params_['n_neighbors']))\n",
    "knn_final.fit(X_train, y_train)\n",
    "y_pred = knn_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3ae1cf-7328-4e18-9a80-952d753cbd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT:\n",
      "Best depth:  {'max_depth': 6}\n",
      "Best F1 score:  0.3434851741411876\n",
      "Test F1 Score:  0.27601156069364163\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "dt_model = RandomizedSearchCV(dt, dt_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, n_jobs=-1)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"DT:\")\n",
    "print(\"Best depth: \", dt_model.best_params_)\n",
    "print(\"Best F1 score: \", dt_model.best_score_)\n",
    "\n",
    "dt_final = DecisionTreeClassifier(max_depth=int(dt_model.best_params_['max_depth']), max_features=512)\n",
    "dt_final.fit(X_train, y_train)\n",
    "y_pred = dt_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31240f3-65ad-4173-b565-541e3a2b0d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Best parameters:  {'max_depth': 38}\n",
      "Best F1 score:  0.57236593578057\n",
      "Test F1 Score:  0.47398843930635837\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RF)\n",
    "rf_model = RandomizedSearchCV(rf, rf_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"Best parameters: \", rf_model.best_params_)\n",
    "print(\"Best F1 score: \", rf_model.best_score_)\n",
    "\n",
    "rf_final = RandomForestClassifier(**rf_model.best_params_)\n",
    "rf_final.fit(X_train, y_train)\n",
    "y_pred_rf = rf_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred_rf, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0dc30f-255e-4cc7-b19d-df305fc3f58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score:  0.30346820809248554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tayya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SVM\n",
    "svc = make_pipeline(StandardScaler(), SGDClassifier(max_iter=3000))\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "# svm_model = RandomizedSearchCV(svc, param_distributions=param_dist, cv=2, scoring=f1_scorer, n_jobs=-1, n_iter=2)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# print(\"SVM\")\n",
    "# print(\"Best params: \", svm_model.best_params_)\n",
    "# print(\"Best F1 score: \", svm_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
